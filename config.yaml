wandb: true
project: griddispatch_challenge
entity: chelly
group: group1
run_name: Attention-action_clip_1.5-${now:%Y%m%dT%H%M%S}
default_run_name: Test-${now:%Y%m%dT%H%M%S}

gen_num:      54
gen_input_dim:  7
embedding_dim:  16
WARMUP_STEPS: 10000          # 开始训练需要收集的时间步数（在达到这个步数之前智能体采用随机策略）
MEMORY_SIZE:  1000000       # 经验池大小
BATCH_SIZE:   256           # 训练一个BATCH的样本数
GAMMA:        0.99          # 衰减系数
TAU:          0.005         # SAC算法超参（Target网络更新的衰减系数）
ALPHA:        0.2           # SAC算法超参（平衡entroy和奖励的重要性）

ACTOR_LR:     3e-4               # Actor网络的学习率 
CRITIC_LR:    3e-4              # Critic网络的学习率 
OBS_DIM:      927                 # 819 873 927
ACT_DIM:      54                  # 动作维度
ACTOR_NUM:    16                # 并行采样的actor数量
ACTOR_DEVICE: 'cpu'
# clamp bounds for Std of action_log
LOG_SIG_MAX:  2.0
LOG_SIG_MIN:  -20.0

SAVE_EVERY_STEPS: 50000     # 保存模型的间隔时间步数
LOG_EVERY_STEPS:  1000      # 打印日志的间隔时间步数

MAX_STEPS:  30000000          # 总共的收集样本数（达到后结束训练）